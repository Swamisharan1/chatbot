{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmqVnT4bKsyL",
        "outputId": "faacb423-6f8a-4c22-b3aa-7f167dcc3810"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MVIt3MFKznP",
        "outputId": "1638db12-451d-4ab5-f833-2f601ce85c51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bLayDd7PKb1N"
      },
      "outputs": [],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration, pipeline\n",
        "from PyPDF2 import PdfReader\n",
        "from gensim import corpora\n",
        "from gensim.models import TfidfModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAi5VzXpLOjv",
        "outputId": "489806f9-338c-4bf1-8662-19a37a3c1fa8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_model():\n",
        "    # Load pre-trained model and tokenizer\n",
        "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "    model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "    # Create a question-answering pipeline\n",
        "    nlp = pipeline('question-answering', model='distilbert-base-uncased-distilled-squad')\n",
        "    return nlp\n"
      ],
      "metadata": {
        "id": "oOTDPzS1KokS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def read_pdf(pdf_file_path):\n",
        "    # Open PDF file\n",
        "    with open(pdf_file_path, 'rb') as f:\n",
        "        pdf = PdfReader(f)\n",
        "        text = \"\"\n",
        "        for page in range(len(pdf.pages)):\n",
        "            text += pdf.pages[page].extract_text()\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "ArDMsd2ILX2D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(text):\n",
        "    # Tokenize the text\n",
        "    tokens = [word_tokenize(t) for t in text.split('\\n') if t]\n",
        "    # Create a dictionary representation of the documents\n",
        "    dictionary = corpora.Dictionary(tokens)\n",
        "    # Create a bag of words corpus\n",
        "    corpus = [dictionary.doc2bow(token) for token in tokens]\n",
        "    # Create a TF-IDF model from the corpus\n",
        "    tfidf = TfidfModel(corpus)\n",
        "    # Store the TF-IDF vectors in a list\n",
        "    vectors = [tfidf[c] for c in corpus]\n",
        "    return vectors, dictionary, tfidf\n",
        "\n"
      ],
      "metadata": {
        "id": "HqH0_O7LLlnf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_questions(nlp, vectors, dictionary, tfidf, text, questions):\n",
        "    # Convert questions to vectors\n",
        "    question_vectors = [tfidf[dictionary.doc2bow(word_tokenize(q))] for q in questions]\n",
        "    # Convert sparse vectors to dense vectors and reshape to 2D\n",
        "    vectors_2d = [np.reshape(np.array(v).mean(axis=0), (1, -1)) for v in vectors]\n",
        "    question_vectors_2d = [np.reshape(np.array(qv).mean(axis=0), (1, -1)) for qv in question_vectors]\n",
        "    # Find the most similar document for each question\n",
        "    answers = []\n",
        "    for i, qv in enumerate(question_vectors_2d):\n",
        "        # Ensure the question vector has the same number of features as the document vectors\n",
        "        if qv.shape[1] < vectors_2d[0].shape[1]:\n",
        "            qv = np.pad(qv, ((0, 0), (0, vectors_2d[0].shape[1] - qv.shape[1])), 'constant')\n",
        "        similarities = [cosine_similarity(qv, dv) for dv in vectors_2d]\n",
        "        most_similar_index = similarities.index(max(similarities))\n",
        "        # Use the pre-trained model to answer the question based on the most similar document\n",
        "        answer = nlp(question=questions[i], context=text)\n",
        "        answers.append(answer['answer'])\n",
        "    return answers\n"
      ],
      "metadata": {
        "id": "d8BPM6NkLoCz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    nlp = load_model()\n",
        "    pdf_file_path = input(\"Enter the path of the PDF file: \")\n",
        "    text = read_pdf(pdf_file_path)\n",
        "    vectors, dictionary, tfidf = process_text(text)\n",
        "    questions = []\n",
        "    while True:\n",
        "        question = input(\"Enter a question (or 'quit' to stop): \")\n",
        "        if question.lower() == 'quit':\n",
        "            break\n",
        "        questions.append(question)\n",
        "    answers = ask_questions(nlp, vectors, dictionary, tfidf, text, questions)\n",
        "    for question, answer in zip(questions, answers):\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Answer: {' '.join(answer)}\\n\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycDQ0Y1YLrAS",
        "outputId": "336178a0-2d49-49a6-fd6f-63aeb25d5a55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path of the PDF file: /content/Hypnosis for Beginners.pdf\n",
            "Enter a question (or 'quit' to stop): what is main topic of this document?\n",
            "Enter a question (or 'quit' to stop): who is the author of this document?\n",
            "Enter a question (or 'quit' to stop): who is james braid?\n",
            "Enter a question (or 'quit' to stop): quit\n",
            "Question: what is main topic of this document?\n",
            "Answer: h y p n o s i s\n",
            "\n",
            "Question: who is the author of this document?\n",
            "Answer: A l e x a n d e r   C a n n o n\n",
            "\n",
            "Question: who is james braid?\n",
            "Answer: t h e   f a t h e r o f   h y p n o t i s m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3wGpgw6LtAh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
